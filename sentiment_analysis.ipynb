{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752c50d-7e07-4f23-8b68-9f0765cff7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities and stuff:\n",
    "import pickle\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange, notebook\n",
    "\n",
    "# pandas options:\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "# nlp stuff:\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# advanced nlp stuff:\n",
    "import spacy\n",
    "import textacy\n",
    "from spacy.lang.en import STOP_WORDS as stop_words\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# ml stuff:\n",
    "import torch\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "\n",
    "# silence:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598db4c-b94a-4b43-923f-c32beec18ac9",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "### About this notebook:\n",
    "In this notebook, we take a look at \"Sentiment Analysis\" models and techniques. See Page 300 of \"Blueprints for Text Analytics Using Python\".\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33c676-c3ce-488b-8007-f297878ed583",
   "metadata": {},
   "source": [
    "---\n",
    "### Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1c30d8-5851-460d-aaf3-2541e58973fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163807</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>A2A8GHFXUG1B28</td>\n",
       "      <td>B0045Z4JAI</td>\n",
       "      <td>Good Decaf... it has a good flavour for a decaf :)</td>\n",
       "      <td>Nice!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195640</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>A1VU337W6PKAR3</td>\n",
       "      <td>B00K0TIC56</td>\n",
       "      <td>I could not ask for a better system for my small greenhouse, easy to set up and nozzles do very ...</td>\n",
       "      <td>I could not ask for a better system for my small greenhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167820</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>A1Z5TT1BBSDLRM</td>\n",
       "      <td>B0012ORBT6</td>\n",
       "      <td>good product at a good price and saves a trip to the store</td>\n",
       "      <td>Four Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104268</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>A4PRXX2G8900X</td>\n",
       "      <td>B005SPI45U</td>\n",
       "      <td>I like the principle of a raw chip - something I can eat with my homemade salsa and guac - but t...</td>\n",
       "      <td>No better alternatives but still tastes bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51961</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>AYETYLNYDIS2S</td>\n",
       "      <td>B00D1HLUP8</td>\n",
       "      <td>Fake China knockoff, you get what you pay for.</td>\n",
       "      <td>Definitely not OEM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified      reviewerID        asin  \\\n",
       "163807        5     False  A2A8GHFXUG1B28  B0045Z4JAI   \n",
       "195640        5      True  A1VU337W6PKAR3  B00K0TIC56   \n",
       "167820        4      True  A1Z5TT1BBSDLRM  B0012ORBT6   \n",
       "104268        1     False   A4PRXX2G8900X  B005SPI45U   \n",
       "51961         1      True   AYETYLNYDIS2S  B00D1HLUP8   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "163807                                                   Good Decaf... it has a good flavour for a decaf :)   \n",
       "195640  I could not ask for a better system for my small greenhouse, easy to set up and nozzles do very ...   \n",
       "167820                                           good product at a good price and saves a trip to the store   \n",
       "104268  I like the principle of a raw chip - something I can eat with my homemade salsa and guac - but t...   \n",
       "51961                                                        Fake China knockoff, you get what you pay for.   \n",
       "\n",
       "                                                            summary  \n",
       "163807                                                        Nice!  \n",
       "195640  I could not ask for a better system for my small greenhouse  \n",
       "167820                                                   Four Stars  \n",
       "104268                 No better alternatives but still tastes bad.  \n",
       "51961                                            Definitely not OEM  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/reviews_5_balanced.json', lines=True)\n",
    "df = df.drop(columns=['reviewTime','unixReviewTime']) ###\n",
    "df = df.rename(columns={'reviewText': 'text'}) ###\n",
    "df.sample(5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d8d9c-8583-4e84-8f20-9288e84fd617",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "### Apply Lexicon based techniques:\n",
    "See Page 300 of \"Blueprints for Text Analytics Using Python\".\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b665f61-3e71-484e-a907-58e2be684fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words in opinion lexicon ['a+', 'abound', 'abounds', 'abundance', 'abundant']\n",
      "Examples of negative words in opinion lexicon ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']\n"
     ]
    }
   ],
   "source": [
    "# download lexicon:\n",
    "# nltk.download('opinion_lexicon')\n",
    "\n",
    "# get lexicon details:\n",
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words in opinion lexicon',\n",
    "      opinion_lexicon.positive()[:5])\n",
    "print('Examples of negative words in opinion lexicon',\n",
    "      opinion_lexicon.negative()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c56402-6724-4640-a887-5e056d35c373",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ab8021-8481-419c-818e-2e35d877fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary which we can use for scoring our review text\n",
    "df.rename(columns={\"reviewText\": \"text\"}, inplace=True)\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary\n",
    "for word in opinion_lexicon.positive():\n",
    "        word_dict[word] = pos_score\n",
    "        \n",
    "# Adding the negative words to the dictionary\n",
    "for word in opinion_lexicon.negative():\n",
    "        word_dict[word] = neg_score\n",
    "\n",
    "# define function to tokenize and score text:\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80281687-98f9-46a8-9f26-bd1c9917e8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188097</th>\n",
       "      <td>As expected</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184654</th>\n",
       "      <td>Works as designed...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text  Bing_Liu_Score\n",
       "188097           As expected            0.00\n",
       "184654  Works as designed...            0.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score text:\n",
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)\n",
    "df[['text','Bing_Liu_Score']].sample(2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdc4ed-3576-433d-a292-364b8ed422f9",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "### Configure BERT Transformer model\n",
    "See Page 312 of \"Blueprints for Text Analytics Using Python\".\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6d0098-cc4b-4d78-bf3b-343f5314e512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bc94f395b949ccb9f3bd484ece292b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model and tokenization:\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', finetuning_task='binary')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e66a9a4-a2cd-4322-8833-ae0dbe05cc19",
   "metadata": {},
   "source": [
    "#### Define tokenization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fcd848-824e-485b-b1e7-d0d633e52e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sentence I want embeddings for.\n",
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2015, 2005, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def get_tokens(text, tokenizer, max_seq_length, add_special_tokens=True):\n",
    "  input_ids = tokenizer.encode(text, \n",
    "                               add_special_tokens=add_special_tokens, \n",
    "                               max_length=max_seq_length,\n",
    "                               pad_to_max_length=True)\n",
    "  attention_mask = [int(id > 0) for id in input_ids]\n",
    "  assert len(input_ids) == max_seq_length\n",
    "  assert len(attention_mask) == max_seq_length\n",
    "  return (input_ids, attention_mask)\n",
    "\n",
    "# TEST:\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "input_ids, attention_mask = get_tokens(text, \n",
    "                                       tokenizer, \n",
    "                                       max_seq_length=30, \n",
    "                                       add_special_tokens = True)\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print (text)\n",
    "print (input_tokens)\n",
    "print (input_ids)\n",
    "print (attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a0f91-1f93-4c51-b6c1-d671d3213525",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82520ad2-2777-4c28-ab39-11a02d1b9a68",
   "metadata": {},
   "source": [
    "#### Define function to label sentiment based on review scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0fe1c68-0122-4e31-bd80-e51b918dcf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = 0\n",
    "df.loc[df['overall'] > 3, 'sentiment'] = 1\n",
    "df.loc[df['overall'] < 3, 'sentiment'] = 0\n",
    "\n",
    "# Removing unecessary columns to keep a simple dataframe \n",
    "df.drop(columns=['overall', 'reviewerID', 'summary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a729c-9cc0-4f30-8844-b02d3d3554a3",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82595067-be92-4b18-9a20-edfe9f4d7de2",
   "metadata": {},
   "source": [
    "#### Split into train and test for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8b231e3-de25-4caa-9d9c-496a8afbd88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],\n",
    "                                                    df['sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['sentiment'])\n",
    "X_train_tokens = X_train.apply(get_tokens, args=(tokenizer, 50))\n",
    "X_test_tokens = X_test.apply(get_tokens, args=(tokenizer, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e637db5-4ce8-4936-a3d5-8ed87b341a7c",
   "metadata": {},
   "source": [
    "#### Convert into Torch Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a56d5763-6011-4eb0-b40d-e6b2a9e3c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([235392, 50])\n",
      "torch.Size([235392, 50])\n",
      "torch.Size([235392])\n"
     ]
    }
   ],
   "source": [
    "input_ids_train = torch.tensor(\n",
    "    [features[0] for features in X_train_tokens.values], dtype=torch.long)\n",
    "input_mask_train = torch.tensor(\n",
    "    [features[1] for features in X_train_tokens.values], dtype=torch.long)\n",
    "label_ids_train = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "\n",
    "print (input_ids_train.shape)\n",
    "print (input_mask_train.shape)\n",
    "print (label_ids_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caecbc1d-94ed-4046-ac47-a7dbaaa76efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train,input_mask_train,label_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a22563ee-2c84-464a-95e4-35bd01bfe474",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = torch.tensor([features[0] for features in X_test_tokens.values], \n",
    "                              dtype=torch.long)\n",
    "input_mask_test = torch.tensor([features[1] for features in X_test_tokens.values], \n",
    "                               dtype=torch.long)\n",
    "label_ids_test = torch.tensor(Y_test.values, \n",
    "                              dtype=torch.long)\n",
    "test_dataset = TensorDataset(input_ids_test, input_mask_test, label_ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61d862-71ed-477c-8bf4-87ace41e785c",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb14f1-4d8b-4983-acd2-d475689565d1",
   "metadata": {},
   "source": [
    "#### Define model params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d80dc6dc-57f0-41aa-81d3-64ba0c090e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training examples =  235392\n",
      "Train batch size  =  64\n",
      "Num training steps in an epoch =  3678\n",
      "Num Epochs =  2\n",
      "Total num training steps =  7356\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "num_train_epochs = 2\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              sampler=train_sampler, \n",
    "                              batch_size=train_batch_size)\n",
    "t_total = len(train_dataloader) * num_train_epochs\n",
    "\n",
    "print (\"Num training examples = \", len(train_dataset))\n",
    "print (\"Train batch size  = \", train_batch_size)\n",
    "print (\"Num training steps in an epoch = \", len(train_dataloader))\n",
    "print (\"Num Epochs = \", num_train_epochs)\n",
    "print (\"Total num training steps = \", t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dec06bf-070c-41ee-b9b7-175b48596da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "adam_epsilon = 1e-8\n",
    "warmup_steps = 0\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c84d39-b057-46ed-86d3-4326c19b65dc",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d62480-5ec0-477a-ac42-d1d80ff30da2",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "### Train BERT Transformer model:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26102b42-c026-4248-88f5-dada22ffe83e",
   "metadata": {},
   "source": [
    "#### Train Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a208a-93ce-425a-bc0e-fa7fa8c3aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c91006570f44e77b8efe259c483a7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.176934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|██████████████              | 1/2 [29:10:21<29:10:21, 105021.52s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7308f7bb537b45d4bf619c1e4afbe02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.195254"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
    "\n",
    "## Put model in 'train' mode\n",
    "model.train()\n",
    "    \n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = notebook.tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "        ## Reset all gradients at start of every iteration\n",
    "        model.zero_grad()\n",
    "        \n",
    "        ## Put the model and the input observations to GPU\n",
    "        model.to(device)\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        ## Identify the inputs to the model\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        ## Forward Pass through the model. Input -> Model -> Output\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        ## Determine the deviation (loss)\n",
    "        loss = outputs[0]\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "        ## Back-propogate the loss (automatically calculates gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        ## Prevent exploding gradients by limiting gradients to 1.0 \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        ## Update the parameters and learning rate\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c8866-37fd-4544-aded-664b3f3a90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model output:\n",
    "model.save_pretrained('outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b457c0-ed43-4ccf-8008-53ee00523451",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7c615-4632-4a07-a7d4-e76bd338b6a9",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "### Evaluate BERT Transformer model:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3809f4-fc89-4b5a-b0e1-0fda38da0752",
   "metadata": {},
   "source": [
    "#### Evaluate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d335f9-2ce4-45c8-9609-8ba3bb10a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 64\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             sampler=test_sampler, \n",
    "                             batch_size=test_batch_size)\n",
    "\n",
    "# Load the pre-trained model that was saved earlier \n",
    "# model = model.from_pretrained('/outputs')\n",
    "\n",
    "# Initialize the prediction and actual labels\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "\n",
    "## Put model in \"eval\" mode\n",
    "model.eval()\n",
    "\n",
    "for batch in notebook.tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "    \n",
    "    ## Put the model and the input observations to GPU\n",
    "    model.to(device)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    ## Do not track any gradients since in 'eval' mode\n",
    "    with torch.no_grad():\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        ## Forward pass through the model\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        ## We get loss since we provided the labels\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "        ## There maybe more than one batch of items in the test dataset\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, \n",
    "                                      inputs['labels'].detach().cpu().numpy(), \n",
    "                                      axis=0)\n",
    "    \n",
    "## Get final loss, predictions and accuracy\n",
    "preds = np.argmax(preds, axis=1)\n",
    "acc_score = accuracy_score(preds, out_label_ids)\n",
    "print ('Accuracy Score on Test data ', acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
